name: Precompute AI Summaries (publish to data)

on:
  workflow_run:
    workflows: ["Daily scrape (JSON publish)"]
    types: [completed]
  workflow_dispatch:

permissions:
  contents: write        # needed to push to data branch
  actions: read          # needed to download artifacts from scrape run

concurrency:
  group: precompute-ai-summaries
  cancel-in-progress: false

jobs:
  run-precompute:
    # Only auto-run after a successful scrape, or allow manual dispatch
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      PYTHONUNBUFFERED: "1"
      PYTHONPATH: ${{ github.workspace }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Download DB artifact from scrape
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          run-id: ${{ github.event.workflow_run.id }}
          name: ofgem-db
          path: artifacts/ofgem-db

      - name: Download JSON artifact from scrape (optional)
        if: ${{ github.event_name == 'workflow_run' }}
        uses: actions/download-artifact@v4
        with:
          run-id: ${{ github.event.workflow_run.id }}
          name: items-json
          path: artifacts/items-json
        continue-on-error: true

      - name: Place DB in workspace
        run: |
          set -euo pipefail
          if [ -f artifacts/ofgem-db/ofgem.db ]; then
            cp artifacts/ofgem-db/ofgem.db ./ofgem.db
          else
            echo "::error::ofgem.db artifact not found. Ensure scrape.yml uploaded it."
            exit 1
          fi
          ls -lh ofgem.db

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install fastapi uvicorn jinja2 python-dotenv openai "httpx<0.28" requests feedparser beautifulsoup4 pypdf tenacity passlib python-multipart itsdangerous
          fi
          python -c "import sys; print('Python:', sys.version)"

      - name: Sanity check imports
        run: |
          python - <<'PY'
          import importlib
          for m in ['storage.db','summariser.model']:
              importlib.import_module(m)
              print('OK import', m)
          print('All imports OK')
          PY

      - name: Run precompute script (fill ai_summary)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          mkdir -p logs
          echo "=== Precompute start $(date -u) ===" >> logs/precompute.log
          PYTHONPATH=. python tools/precompute_summaries.py >> logs/precompute.log 2>&1 || echo "Script failed, continuing"

      - name: Export updated JSON (items.json)
        run: |
          mkdir -p public
          python tools/export_json.py
          test -f public/items.json || (echo "::error:: public/items.json was not created" && exit 1)
          ls -lh public/items.json | cat
          head -40 public/items.json || true

      - name: Upload logs artifact
        uses: actions/upload-artifact@v4
        with:
          name: precompute-logs
          path: logs/precompute.log
          retention-days: 7

      - name: Upload precomputed DB
        uses: actions/upload-artifact@v4
        with:
          name: ofgem-db-precomputed
          path: ofgem.db
          if-no-files-found: error
          retention-days: 7

      - name: Upload precomputed JSON
        uses: actions/upload-artifact@v4
        with:
          name: items-json-precomputed
          path: public/items.json
          retention-days: 7

      - name: Push items.json to data branch
        run: |
          set -euo pipefail
          # Keep a copy while switching branches
          cp public/items.json "$RUNNER_TEMP/items.json"

          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git fetch origin data || true
          git checkout -B data
          git reset --hard

          mkdir -p public
          cp "$RUNNER_TEMP/items.json" public/items.json

          git add public/items.json
          if git diff --cached --quiet; then
            echo "No changes to commit on data."
          else
            git commit -m "Precompute: update items.json ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"
            git push origin data --force
          fi
